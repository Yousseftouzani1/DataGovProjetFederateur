import pandas as pd
import numpy as np
from ydata_profiling import ProfileReport
import re

def clean_dataframe(df: pd.DataFrame, config: dict = None) -> pd.DataFrame:
    """
    Implements the Data Cleaning Pipeline as per CDC Section 6.4.
    
    Pipeline Steps:
    1. Remove Duplicates (KPI: 0% duplicates)
    2. Handle Missing Values (KPI: <5% missing)
    3. Remove Outliers (IQR Method) (KPI: <2% outliers)
    4. Normalize Data (Lowercasing, stripping whitespace)
    5. Validate (Constraint checks)
    """
    if config is None:
        config = {}
    
    # ---------------------------------------------------------
    # 1. Remove Duplicates
    # ---------------------------------------------------------
    initial_rows = len(df)
    df = df.drop_duplicates()
    df = df.copy() # Ensure we have a fresh copy to avoid SettingWithCopyWarning
    print(f"[Pipeline] Removed {initial_rows - len(df)} duplicate rows.")
    
    # ---------------------------------------------------------
    # 2. Handle Missing Values
    # ---------------------------------------------------------
    # Strategy can be 'drop', 'mean', 'median', 'mode'. Default is 'drop' rows with any missing.
    missing_strategy = config.get("missing_strategy", "drop")
    
    if missing_strategy == "drop":
        df = df.dropna(how='any') # Strict drop
    elif missing_strategy == "mean":
        numeric_cols = df.select_dtypes(include=np.number).columns
        # Avoid SettingWithCopyWarning by ensuring we work on a fresh copy if needed, or use proper assignment
        # For simple imputation, strict assignment works efficiently
        for col in numeric_cols:
            if df[col].isnull().any():
                df[col] = df[col].fillna(df[col].mean())
        
        # Fill non-numeric with mode or empty
        for col in df.select_dtypes(exclude=np.number).columns:
             if not df[col].empty and df[col].isnull().any():
                df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else "")
    elif missing_strategy == "median":
        numeric_cols = df.select_dtypes(include=np.number).columns
        for col in numeric_cols:
             if df[col].isnull().any():
                df[col] = df[col].fillna(df[col].median())
        
        for col in df.select_dtypes(exclude=np.number).columns:
             if not df[col].empty and df[col].isnull().any():
                df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else "")
    
    # ---------------------------------------------------------
    # 3. Remove Outliers (IQR Method - CDC Algo 4)
    # ---------------------------------------------------------
    # Apply to all numeric columns unless specified
    outlier_multiplier = config.get("iqr_multiplier", 1.5)
    numeric_cols = df.select_dtypes(include=np.number).columns
    
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - (outlier_multiplier * IQR)
        upper_bound = Q3 + (outlier_multiplier * IQR)
        
        # Filter
        original_len = len(df)
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
        removed = original_len - len(df)
        if removed > 0:
            print(f"[Pipeline] Removed {removed} outliers from column '{col}' using IQR {outlier_multiplier}.")
            
    # ---------------------------------------------------------
    # 4. Normalize Data
    # ---------------------------------------------------------
    # Lowercase string columns and strip whitespace
    string_cols = df.select_dtypes(include='object').columns
    for col in string_cols:
        df[col] = df[col].astype(str).str.lower().str.strip()
        
    # ---------------------------------------------------------
    # 5. Validate (Basic Type Check / additional logic can go here)
    # ---------------------------------------------------------
    # Ensure no NaN remains if possible, or cast types
    
    return df

def generate_profile(df: pd.DataFrame) -> dict:
    """
    Generates a ydata-profiling report and returns metadata summary.
    Returns:
        dict: Summary statistics and path to HTML report (if saved, handled by caller)
    """
    profile = ProfileReport(df, title="Profiling Report", minimal=True)
    description = profile.get_description()
    
    # Extract key stats for metadata
    stats = {
        "n_rows": int(description["table"]["n"]),
        "n_cols": int(description["table"]["n_var"]),
        "duplicates": int(description["table"]["n_duplicates"]),
        "missing_cells": int(description["table"]["n_cells_missing"]),
        "missing_percentage": float(description["table"]["p_cells_missing"]) * 100
    }
    
    # The actual HTML report should be generated by the caller using profile.to_file() 
    # or we return the profile object. For flexibility, let's return the profile object + stats.
    return profile, stats
